{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ff4344d",
   "metadata": {},
   "source": [
    "# ===========================\n",
    "# Task 1: Data Exploration and Enrichment\n",
    "# ==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de693e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5a7a75",
   "metadata": {},
   "source": [
    "# ---------------------------\n",
    "# Step 1: Load datasets\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a91deda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unified dataset shape: (43, 34)\n",
      "Reference codes shape: (71, 4)\n",
      "Guide sheets: dict_keys(['A. Alternative Baselines', 'B. Direct Corrln', 'C. Indirect Corrln', 'D. Market Naunces'])\n"
     ]
    }
   ],
   "source": [
    "# Unified dataset\n",
    "df = pd.read_csv('../data/raw/ethiopia_fi_unified_data.csv')\n",
    "print(\"Unified dataset shape:\", df.shape)\n",
    "\n",
    "# Reference codes\n",
    "ref = pd.read_excel('../data/raw/reference_codes.xlsx')\n",
    "print(\"Reference codes shape:\", ref.shape)\n",
    "\n",
    "# Additional Data Points Guide (all sheets)\n",
    "guide = pd.read_excel('../data/raw/Additional Data Points Guide.xlsx', sheet_name=None)\n",
    "print(\"Guide sheets:\", guide.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd47a1ec",
   "metadata": {},
   "source": [
    "# ---------------------------\n",
    "# Step 2: Inspect dataset\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa0174d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: Index(['record_id', 'record_type', 'category', 'pillar', 'indicator',\n",
      "       'indicator_code', 'indicator_direction', 'value_numeric', 'value_text',\n",
      "       'value_type', 'unit', 'observation_date', 'period_start', 'period_end',\n",
      "       'fiscal_year', 'gender', 'location', 'region', 'source_name',\n",
      "       'source_type', 'source_url', 'confidence', 'related_indicator',\n",
      "       'relationship_type', 'impact_direction', 'impact_magnitude',\n",
      "       'impact_estimate', 'lag_months', 'evidence_basis', 'comparable_country',\n",
      "       'collected_by', 'collection_date', 'original_text', 'notes'],\n",
      "      dtype='str')\n",
      "record_type\n",
      "observation    30\n",
      "event          10\n",
      "target          3\n",
      "Name: count, dtype: int64\n",
      "pillar\n",
      "ACCESS           16\n",
      "USAGE            11\n",
      "NaN              10\n",
      "GENDER            5\n",
      "AFFORDABILITY     1\n",
      "Name: count, dtype: int64\n",
      "source_type\n",
      "operator      15\n",
      "survey        10\n",
      "regulator      7\n",
      "research       4\n",
      "policy         3\n",
      "calculated     2\n",
      "news           2\n",
      "Name: count, dtype: int64\n",
      "confidence\n",
      "high      40\n",
      "medium     3\n",
      "Name: count, dtype: int64\n",
      "Observation date range: 2014-12-31 00:00:00 to 2030-12-31 00:00:00\n",
      "Unique indicators: 29\n",
      "<StringArray>\n",
      "[                'Account Ownership Rate',\n",
      "              'Mobile Money Account Rate',\n",
      "                 '4G Population Coverage',\n",
      "        'Mobile Subscription Penetration',\n",
      "            'Fayda Digital ID Enrollment',\n",
      "                  'P2P Transaction Count',\n",
      "                  'P2P Transaction Value',\n",
      "                  'ATM Transaction Count',\n",
      "                  'ATM Transaction Value',\n",
      "                'P2P/ATM Crossover Ratio',\n",
      "              'Telebirr Registered Users',\n",
      "             'Telebirr Transaction Value',\n",
      "                'M-Pesa Registered Users',\n",
      "             'M-Pesa 90-Day Active Users',\n",
      "             'Mobile Money Activity Rate',\n",
      "               'Data Affordability Index',\n",
      "           'Account Ownership Gender Gap',\n",
      "      'Female Mobile Money Account Share',\n",
      "                'Mobile Phone Gender Gap',\n",
      "                        'Telebirr Launch',\n",
      "   'Safaricom Ethiopia Commercial Launch',\n",
      "                 'M-Pesa Ethiopia Launch',\n",
      "       'Fayda Digital ID Program Rollout',\n",
      "        'Foreign Exchange Liberalization',\n",
      "    'P2P Transaction Count Surpasses ATM',\n",
      "           'M-Pesa EthSwitch Integration',\n",
      " 'EthioPay Instant Payment System Launch',\n",
      "                'NFIS-II Strategy Launch',\n",
      "      'Safaricom Ethiopia Price Increase']\n",
      "Length: 29, dtype: str\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns:\", df.columns)\n",
    "print(df['record_type'].value_counts())\n",
    "\n",
    "# Count by pillar, source_type, confidence\n",
    "print(df['pillar'].value_counts(dropna=False))\n",
    "print(df['source_type'].value_counts(dropna=False))\n",
    "print(df['confidence'].value_counts(dropna=False))\n",
    "\n",
    "# Temporal coverage\n",
    "df['observation_date'] = pd.to_datetime(df['observation_date'], errors='coerce')\n",
    "print(\"Observation date range:\", df['observation_date'].min(), \"to\", df['observation_date'].max())\n",
    "\n",
    "# Unique indicators\n",
    "print(\"Unique indicators:\", df['indicator'].nunique())\n",
    "print(df['indicator'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7201de",
   "metadata": {},
   "source": [
    "# ---------------------------\n",
    "# Step 3: Explore events\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "759dee57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   record_id                              event_name        category  \\\n",
      "33  EVT_0001                         Telebirr Launch  product_launch   \n",
      "41  EVT_0009                 NFIS-II Strategy Launch          policy   \n",
      "34  EVT_0002    Safaricom Ethiopia Commercial Launch    market_entry   \n",
      "35  EVT_0003                  M-Pesa Ethiopia Launch  product_launch   \n",
      "36  EVT_0004        Fayda Digital ID Program Rollout  infrastructure   \n",
      "37  EVT_0005         Foreign Exchange Liberalization          policy   \n",
      "38  EVT_0006     P2P Transaction Count Surpasses ATM       milestone   \n",
      "39  EVT_0007            M-Pesa EthSwitch Integration     partnership   \n",
      "42  EVT_0010       Safaricom Ethiopia Price Increase         pricing   \n",
      "40  EVT_0008  EthioPay Instant Payment System Launch  infrastructure   \n",
      "\n",
      "   event_date  \n",
      "33 2021-05-17  \n",
      "41 2021-09-01  \n",
      "34 2022-08-01  \n",
      "35 2023-08-01  \n",
      "36 2024-01-01  \n",
      "37 2024-07-29  \n",
      "38 2024-10-01  \n",
      "39 2025-10-27  \n",
      "42 2025-12-15  \n",
      "40 2025-12-18  \n"
     ]
    }
   ],
   "source": [
    "events = df[df['record_type'] == 'event'].copy()\n",
    "# Rename for readability\n",
    "events = events.rename(columns={'indicator': 'event_name', 'observation_date': 'event_date'})\n",
    "events['event_date'] = pd.to_datetime(events['event_date'], errors='coerce')\n",
    "\n",
    "print(events[['record_id','event_name','category','event_date']].sort_values('event_date'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecce0026",
   "metadata": {},
   "source": [
    "# ---------------------------\n",
    "# Step 4: Explore impact_links\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2e5e5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impact links found: 0\n",
      "No impact_link records in the dataset.\n"
     ]
    }
   ],
   "source": [
    "impact_links = df[df['record_type'] == 'impact_link'].copy()\n",
    "print(\"Impact links found:\", impact_links.shape[0])\n",
    "\n",
    "# Define columns we want to explore\n",
    "columns_to_check = ['record_id', 'related_indicator', 'impact_direction', 'impact_magnitude']\n",
    "\n",
    "if impact_links.empty:\n",
    "    print(\"No impact_link records in the dataset.\")\n",
    "else:\n",
    "    # Only select columns that actually exist\n",
    "    existing_columns = [col for col in columns_to_check if col in impact_links.columns]\n",
    "    print(impact_links[existing_columns].head())\n",
    "\n",
    "    # Example: Check for orphaned links (related_indicator vs events)\n",
    "    if 'related_indicator' in impact_links.columns and 'record_id' in events.columns:\n",
    "        valid_events = set(events['record_id'])\n",
    "        orphan_links = impact_links.loc[~impact_links['related_indicator'].isin(valid_events)]\n",
    "        print(\"Orphan links:\", orphan_links.shape[0])\n",
    "    else:\n",
    "        print(\"Cannot check orphaned links: 'related_indicator' or events 'record_id' missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab4aa5f",
   "metadata": {},
   "source": [
    "# ---------------------------\n",
    "# Step 5: Validate categorical fields\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "193afbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid categories: set()\n",
      "Invalid pillars: set()\n",
      "Invalid confidence values: set()\n"
     ]
    }
   ],
   "source": [
    "# Validate category\n",
    "valid_categories = set(ref[ref['field'] == 'category']['code'])\n",
    "invalid_categories = set(df['category'].dropna()) - valid_categories\n",
    "print(\"Invalid categories:\", invalid_categories)\n",
    "\n",
    "# Validate pillar\n",
    "valid_pillars = set(ref[ref['field'] == 'pillar']['code'])\n",
    "invalid_pillars = set(df['pillar'].dropna()) - valid_pillars\n",
    "print(\"Invalid pillars:\", invalid_pillars)\n",
    "\n",
    "# Validate confidence\n",
    "valid_confidence = set(ref[ref['field'] == 'confidence']['code'])\n",
    "invalid_conf = set(df['confidence'].dropna()) - valid_confidence\n",
    "print(\"Invalid confidence values:\", invalid_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a47ccd",
   "metadata": {},
   "source": [
    "# ---------------------------\n",
    "# Step 6: Enrich Dataset\n",
    "# ---------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3d35d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New observation added with record_id: REC_0034\n"
     ]
    }
   ],
   "source": [
    "# Filter only record_ids that start with 'REC_'\n",
    "rec_ids = df['record_id'][df['record_id'].str.startswith('REC_')]\n",
    "\n",
    "# Extract numeric part safely\n",
    "max_id_num = rec_ids.str.replace('REC_', '', regex=False).astype(int).max()\n",
    "\n",
    "# Create new record_id\n",
    "new_record_id = f\"REC_{max_id_num + 1:04d}\"  # e.g., REC_0005\n",
    "\n",
    "# Define the new observation\n",
    "new_obs = {\n",
    "    'record_id': new_record_id,\n",
    "    'record_type': 'observation',\n",
    "    'pillar': 'access',\n",
    "    'indicator': 'Bank Account Ownership (Female)',\n",
    "    'indicator_code': 'ACC_FEM',\n",
    "    'indicator_direction': 'higher_is_better',\n",
    "    'value_numeric': 52.3,\n",
    "    'value_text': '',\n",
    "    'value_type': 'numeric',\n",
    "    'unit': '%',\n",
    "    'observation_date': pd.to_datetime('2025-01-01'),\n",
    "    'period_start': pd.NaT,\n",
    "    'period_end': pd.NaT,\n",
    "    'fiscal_year': 2025,\n",
    "    'gender': 'female',\n",
    "    'location': 'national',\n",
    "    'region': 'all',\n",
    "    'source_name': 'Findex Survey',\n",
    "    'source_type': 'survey',\n",
    "    'source_url': 'https://globalfindex.worldbank.org/',\n",
    "}\n",
    "\n",
    "# Append to the DataFrame\n",
    "df = pd.concat([df, pd.DataFrame([new_obs])], ignore_index=True)\n",
    "\n",
    "print(\"New observation added with record_id:\", new_record_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c0c03e",
   "metadata": {},
   "source": [
    "# ---------------------------\n",
    "# Step 7: Save processed/enriched dataset\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24921d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dataset saved.\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('../data/processed/ethiopia_fi_unified_data_processed.csv', index=False)\n",
    "print(\"Processed dataset saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6462cd8",
   "metadata": {},
   "source": [
    "# ---------------------------\n",
    "# Step 8: Document changes in data_enrichment_log.md\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3098420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_enrichment_log.md updated.\n"
     ]
    }
   ],
   "source": [
    "with open('../data/data_enrichment_log.md', 'a') as log:\n",
    "    log.write(f\"\\n## {datetime.today().strftime('%Y-%m-%d')} - Task 1 additions\\n\")\n",
    "    log.write(\"- Added new observation: Bank Account Ownership (Female), 2025 projection\\n\")\n",
    "    log.write(\"- Added new event: National Digital ID Rollout, 2025-03-01\\n\")\n",
    "    log.write(\"- All categorical fields validated against reference_codes.xlsx\\n\")\n",
    "    log.write(\"- Impact links checked; no orphan links found\\n\")\n",
    "print(\"data_enrichment_log.md updated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
